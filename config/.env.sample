# LLM Provider Configuration
# Copy this file to .env and fill in your actual values

# Ollama (Default Provider)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=deepseek-r1:latest
OLLAMA_TIMEOUT=300

# Llama.cpp (Fallback Provider)
LLAMACPP_BASE_URL=http://localhost:8080
LLAMACPP_MODEL_PATH=./models/
LLAMACPP_TIMEOUT=300

# LocalAI
LOCALAI_BASE_URL=http://localhost:8080
LOCALAI_API_KEY=your_localai_key_here
LOCALAI_MODEL=gpt-3.5-turbo

# LLM Studio
LLMSTUDIO_BASE_URL=http://localhost:1234
LLMSTUDIO_API_KEY=your_llmstudio_key_here
LLMSTUDIO_MODEL=local-model

# OpenAI (Emergency Provider)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_MODEL=gpt-4
OPENAI_TIMEOUT=60

# Gemini (Auxiliary Provider)
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_BASE_URL=https://generativelanguage.googleapis.com/v1beta
GEMINI_MODEL=gemini-pro
GEMINI_TIMEOUT=60

# Anthropic
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_BASE_URL=https://api.anthropic.com/v1
ANTHROPIC_MODEL=claude-3-sonnet-20240229
ANTHROPIC_TIMEOUT=60

# Hugging Face
HUGGINGFACE_API_KEY=your_huggingface_token_here
HUGGINGFACE_BASE_URL=https://api-inference.huggingface.co/models
HUGGINGFACE_MODEL=microsoft/DialoGPT-large
HUGGINGFACE_TIMEOUT=60

# Provider Priority (comma-separated, in order of preference)
PROVIDER_PRIORITY=ollama,llamacpp,localai,llmstudio,openai,gemini,anthropic,huggingface

# Enterprise Settings
ENTERPRISE_MODE=true
LOG_LEVEL=INFO
MAX_RETRIES=3
FALLBACK_ENABLED=true
